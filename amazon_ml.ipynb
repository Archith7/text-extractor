{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: imutils in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text bounding box coordinates:\n",
      "Start (X, Y): (518, 569), End (X, Y): (601, 604)\n",
      "Start (X, Y): (435, 563), End (X, Y): (537, 604)\n",
      "Start (X, Y): (432, 336), End (X, Y): (614, 384)\n",
      "Start (X, Y): (473, 633), End (X, Y): (563, 668)\n",
      "Start (X, Y): (470, 726), End (X, Y): (598, 800)\n",
      "Start (X, Y): (499, 668), End (X, Y): (582, 704)\n",
      "Output saved to C:\\Users\\archi\\Desktop\\detected\\11111.jpg\n"
     ]
    }
   ],
   "source": [
    "#EAST model that will box the texts and add to a directory \"detected\", check last lines of this cell \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "def decode_predictions(scores, geometry, min_confidence=0.5):\n",
    "    (num_rows, num_cols) = scores.shape[2:4]\n",
    "    rectangles = []\n",
    "    confidences = []\n",
    "    \n",
    "    for y in range(0, num_rows):\n",
    "        scores_data = scores[0, 0, y]\n",
    "        x_data0 = geometry[0, 0, y]\n",
    "        x_data1 = geometry[0, 1, y]\n",
    "        x_data2 = geometry[0, 2, y]\n",
    "        x_data3 = geometry[0, 3, y]\n",
    "        angles_data = geometry[0, 4, y]\n",
    "        \n",
    "        for x in range(0, num_cols):\n",
    "            if scores_data[x] < min_confidence:\n",
    "                continue\n",
    "            \n",
    "            offset_x, offset_y = (x * 4.0, y * 4.0)\n",
    "            angle = angles_data[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            \n",
    "            h = x_data0[x] + x_data2[x]\n",
    "            w = x_data1[x] + x_data3[x]\n",
    "            \n",
    "            end_x = int(offset_x + (cos * x_data1[x]) + (sin * x_data2[x]))\n",
    "            end_y = int(offset_y - (sin * x_data1[x]) + (cos * x_data2[x]))\n",
    "            start_x = int(end_x - w)\n",
    "            start_y = int(end_y - h)\n",
    "            \n",
    "            rectangles.append((start_x, start_y, end_x, end_y))\n",
    "            confidences.append(scores_data[x])\n",
    "    \n",
    "    return (rectangles, confidences)\n",
    "\n",
    "def detect_text_east(image_path, model_path, output_path=None):\n",
    "    try:\n",
    "        # Load the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "        orig = img.copy()\n",
    "        (H, W) = img.shape[:2]\n",
    "        \n",
    "        # Define the new image dimensions\n",
    "        newW, newH = (320, 320)\n",
    "        rW = W / float(newW)\n",
    "        rH = H / float(newH)\n",
    "        \n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (newW, newH))\n",
    "\n",
    "        # Load pre-trained EAST model\n",
    "        net = cv2.dnn.readNet(model_path)\n",
    "\n",
    "        # Prepare the image for EAST model\n",
    "        blob = cv2.dnn.blobFromImage(img, 1.0, (newW, newH), \n",
    "                                     (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        \n",
    "        # Get scores and geometry data from the model\n",
    "        (scores, geometry) = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \n",
    "                                          \"feature_fusion/concat_3\"])\n",
    "        \n",
    "        # Decode the predictions to extract the bounding boxes\n",
    "        rectangles, confidences = decode_predictions(scores, geometry, 0.5)\n",
    "\n",
    "        # Apply non-maxima suppression to remove overlapping boxes\n",
    "        boxes = non_max_suppression(np.array(rectangles), probs=confidences)\n",
    "        \n",
    "        # Scale bounding boxes back to original image size\n",
    "        boxes = [(int(rH * startX), int(rW * startY), int(rH * endX), int(rW * endY))\n",
    "                 for (startX, startY, endX, endY) in boxes]\n",
    "        print(\"Detected text bounding box coordinates:\")\n",
    "        for box in boxes:\n",
    "            print(f\"Start (X, Y): ({box[0]}, {box[1]}), End (X, Y): ({box[2]}, {box[3]})\")\n",
    "        # Draw bounding boxes on the image\n",
    "        for (startX, startY, endX, endY) in boxes:\n",
    "            cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        \n",
    "        # If an output path is provided, save the image, else show it\n",
    "        if output_path:\n",
    "            cv2.imwrite(output_path, orig)\n",
    "            print(f\"Output saved to {output_path}\")\n",
    "        else:\n",
    "            cv2.imshow(\"Text Detection\", orig)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        return boxes, orig\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# Change the paths below according to your system\n",
    "image_path = r\"C:\\Users\\archi\\Downloads\\processed_images\\processed_images\\51NIEOGNLSS.jpg\"  # Path to your input image\n",
    "model_path = r\"C:\\Users\\archi\\Downloads\\frozen_east_text_detection\\frozen_east_text_detection.pb\"  # Path to the EAST model\n",
    "output_path = r\"C:\\Users\\archi\\Desktop\\detected\\11111.jpg\"  # Path to save the output (optional)\n",
    "# \"C:\\Users\\archi\\Desktop\\3-1.txt\"\n",
    "# Call the function to detect text and save the output image\n",
    "boxes, image_with_boxes = detect_text_east(image_path, model_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text bounding box coordinates:\n",
      "Start (X, Y): (518, 569), End (X, Y): (601, 604)\n",
      "Cropped image saved at: C:\\Users\\archi\\Desktop\\cropped_images\\51NIEOGNLSS_1.jpg\n",
      "Start (X, Y): (435, 563), End (X, Y): (537, 604)\n",
      "Cropped image saved at: C:\\Users\\archi\\Desktop\\cropped_images\\51NIEOGNLSS_2.jpg\n",
      "Start (X, Y): (432, 336), End (X, Y): (614, 384)\n",
      "Cropped image saved at: C:\\Users\\archi\\Desktop\\cropped_images\\51NIEOGNLSS_3.jpg\n",
      "Start (X, Y): (473, 633), End (X, Y): (563, 668)\n",
      "Cropped image saved at: C:\\Users\\archi\\Desktop\\cropped_images\\51NIEOGNLSS_4.jpg\n",
      "Start (X, Y): (470, 726), End (X, Y): (598, 800)\n",
      "Cropped image saved at: C:\\Users\\archi\\Desktop\\cropped_images\\51NIEOGNLSS_5.jpg\n",
      "Start (X, Y): (499, 668), End (X, Y): (582, 704)\n",
      "Cropped image saved at: C:\\Users\\archi\\Desktop\\cropped_images\\51NIEOGNLSS_6.jpg\n"
     ]
    }
   ],
   "source": [
    "#the boxed parts with EAST are cropped and saved to a directory \"cropped_images\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "def decode_predictions(scores, geometry, min_confidence=0.5):\n",
    "    (num_rows, num_cols) = scores.shape[2:4]\n",
    "    rectangles = []\n",
    "    confidences = []\n",
    "    \n",
    "    for y in range(0, num_rows):\n",
    "        scores_data = scores[0, 0, y]\n",
    "        x_data0 = geometry[0, 0, y]\n",
    "        x_data1 = geometry[0, 1, y]\n",
    "        x_data2 = geometry[0, 2, y]\n",
    "        x_data3 = geometry[0, 3, y]\n",
    "        angles_data = geometry[0, 4, y]\n",
    "        \n",
    "        for x in range(0, num_cols):\n",
    "            if scores_data[x] < min_confidence:\n",
    "                continue\n",
    "            \n",
    "            offset_x, offset_y = (x * 4.0, y * 4.0)\n",
    "            angle = angles_data[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            \n",
    "            h = x_data0[x] + x_data2[x]\n",
    "            w = x_data1[x] + x_data3[x]\n",
    "            \n",
    "            end_x = int(offset_x + (cos * x_data1[x]) + (sin * x_data2[x]))\n",
    "            end_y = int(offset_y - (sin * x_data1[x]) + (cos * x_data2[x]))\n",
    "            start_x = int(end_x - w)\n",
    "            start_y = int(end_y - h)\n",
    "            \n",
    "            rectangles.append((start_x, start_y, end_x, end_y))\n",
    "            confidences.append(scores_data[x])\n",
    "    \n",
    "    return (rectangles, confidences)\n",
    "\n",
    "def detect_and_save_cropped_text(image_path, model_path, output_folder):\n",
    "    try:\n",
    "        # Load the image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "        orig = img.copy()\n",
    "        (H, W) = img.shape[:2]\n",
    "        \n",
    "        # Define the new image dimensions\n",
    "        newW, newH = (320, 320)\n",
    "        rW = W / float(newW)\n",
    "        rH = H / float(newH)\n",
    "        \n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (newW, newH))\n",
    "\n",
    "        # Load pre-trained EAST model\n",
    "        net = cv2.dnn.readNet(model_path)\n",
    "\n",
    "        # Prepare the image for EAST model\n",
    "        blob = cv2.dnn.blobFromImage(img, 1.0, (newW, newH), \n",
    "                                     (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        \n",
    "        # Get scores and geometry data from the model\n",
    "        (scores, geometry) = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \n",
    "                                          \"feature_fusion/concat_3\"])\n",
    "        \n",
    "        # Decode the predictions to extract the bounding boxes\n",
    "        rectangles, confidences = decode_predictions(scores, geometry, 0.5)\n",
    "\n",
    "        # Apply non-maxima suppression to remove overlapping boxes\n",
    "        boxes = non_max_suppression(np.array(rectangles), probs=confidences)\n",
    "        \n",
    "        # Scale bounding boxes back to original image size\n",
    "        boxes = [(int(rH * startX), int(rW * startY), int(rH * endX), int(rW * endY))\n",
    "                 for (startX, startY, endX, endY) in boxes]\n",
    "\n",
    "        # Extract the base name of the image (without extension)\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        print(\"Detected text bounding box coordinates:\")\n",
    "        for idx, (startX, startY, endX, endY) in enumerate(boxes, start=1):\n",
    "            print(f\"Start (X, Y): ({startX}, {startY}), End (X, Y): ({endX}, {endY})\")\n",
    "            \n",
    "            # Crop the detected text region from the original image\n",
    "            cropped_img = orig[startY:endY, startX:endX]\n",
    "            \n",
    "            # Save the cropped image with incremental names\n",
    "            cropped_image_path = os.path.join(output_folder, f\"{base_name}_{idx}.jpg\")\n",
    "            cv2.imwrite(cropped_image_path, cropped_img)\n",
    "            print(f\"Cropped image saved at: {cropped_image_path}\")\n",
    "\n",
    "        return boxes, orig\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# Change the paths below according to your system\n",
    "image_path = r\"C:\\Users\\archi\\Downloads\\processed_images\\processed_images\\51NIEOGNLSS.jpg\"  # Path to your input image\n",
    "model_path = r\"C:\\Users\\archi\\Downloads\\frozen_east_text_detection\\frozen_east_text_detection.pb\"  # Path to the EAST model\n",
    "output_folder = r\"C:\\Users\\archi\\Desktop\\cropped_images\"  # Folder to save the cropped images\n",
    "\n",
    "# Call the function to detect text and save the cropped text images\n",
    "boxes, image_with_boxes = detect_and_save_cropped_text(image_path, model_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlepaddle in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: paddleocr in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.13 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (1.26.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (10.4.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (5.1.1)\n",
      "Requirement already satisfied: astor in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (3.3.0)\n",
      "Requirement already satisfied: protobuf<=3.20.2,>=3.1.0 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddlepaddle) (3.20.0)\n",
      "Requirement already satisfied: shapely in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (2.0.6)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (0.24.0)\n",
      "Requirement already satisfied: imgaug in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (0.4.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (1.3.0.post5)\n",
      "Requirement already satisfied: lmdb in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (1.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (4.66.5)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (3.9.7)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (4.9.0.80)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (4.10.0.84)\n",
      "Requirement already satisfied: cython in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (3.0.11)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (6.0)\n",
      "Requirement already satisfied: python-docx in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (1.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (4.12.2)\n",
      "Requirement already satisfied: fonttools>=4.24.0 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (4.53.1)\n",
      "Requirement already satisfied: fire>=0.3.0 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (0.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paddleocr) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fire>=0.3.0->paddleocr) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fire>=0.3.0->paddleocr) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->paddleocr) (2.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (3.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->paddlepaddle) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug->paddleocr) (1.11.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug->paddleocr) (3.9.2)\n",
      "Requirement already satisfied: imageio in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug->paddleocr) (2.35.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->paddleocr) (3.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->paddleocr) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->paddleocr) (23.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->paddleocr) (0.4)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx->paddleocr) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx->paddleocr) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->paddleocr) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->paddleocr) (2.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->paddleocr) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\archi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install paddlepaddle paddleocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/11/29 22:58:21] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\archi/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\archi/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\archi\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\archi/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/11/29 22:58:23] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.23865723609924316\n",
      "[2024/11/29 22:58:23] ppocr DEBUG: cls num  : 1, elapsed : 0.07958817481994629\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: rec_res num  : 1, elapsed : 0.13476109504699707\n",
      "Extracted text from region 1: pots\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.009999513626098633\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: cls num  : 1, elapsed : 0.009006261825561523\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: rec_res num  : 1, elapsed : 0.03550863265991211\n",
      "Extracted text from region 2: plant\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.21050262451171875\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: cls num  : 3, elapsed : 0.05000615119934082\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: rec_res num  : 3, elapsed : 0.13401389122009277\n",
      "Extracted text from region 3: CFISHEgarden\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.010999679565429688\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: cls num  : 1, elapsed : 0.009001016616821289\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: rec_res num  : 1, elapsed : 0.03800010681152344\n",
      "Extracted text from region 4: 15cm\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.2110137939453125\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: rec_res num  : 0, elapsed : 0.0\n",
      "No text detected in region 5\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.012999296188354492\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: cls num  : 1, elapsed : 0.00899815559387207\n",
      "[2024/11/29 22:58:24] ppocr DEBUG: rec_res num  : 1, elapsed : 0.04006695747375488\n",
      "Extracted text from region 6: pprox)\n"
     ]
    }
   ],
   "source": [
    "#used paddle ocr, that will extract the text from the boxed parts\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "# EAST Text Detection\n",
    "def decode_predictions(scores, geometry, min_confidence=0.5):\n",
    "    (num_rows, num_cols) = scores.shape[2:4]\n",
    "    rectangles = []\n",
    "    confidences = []\n",
    "    \n",
    "    for y in range(0, num_rows):\n",
    "        scores_data = scores[0, 0, y]\n",
    "        x_data0 = geometry[0, 0, y]\n",
    "        x_data1 = geometry[0, 1, y]\n",
    "        x_data2 = geometry[0, 2, y]\n",
    "        x_data3 = geometry[0, 3, y]\n",
    "        angles_data = geometry[0, 4, y]\n",
    "        \n",
    "        for x in range(0, num_cols):\n",
    "            if scores_data[x] < min_confidence:\n",
    "                continue\n",
    "            \n",
    "            offset_x, offset_y = (x * 4.0, y * 4.0)\n",
    "            angle = angles_data[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            \n",
    "            h = x_data0[x] + x_data2[x]\n",
    "            w = x_data1[x] + x_data3[x]\n",
    "            \n",
    "            end_x = int(offset_x + (cos * x_data1[x]) + (sin * x_data2[x]))\n",
    "            end_y = int(offset_y - (sin * x_data1[x]) + (cos * x_data2[x]))\n",
    "            start_x = int(end_x - w)\n",
    "            start_y = int(end_y - h)\n",
    "            \n",
    "            rectangles.append((start_x, start_y, end_x, end_y))\n",
    "            confidences.append(scores_data[x])\n",
    "    \n",
    "    return (rectangles, confidences)\n",
    "\n",
    "# Function to detect text regions using EAST and pass them to OCR\n",
    "def detect_and_extract_text(image_path, east_model_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "    orig = img.copy()\n",
    "    (H, W) = img.shape[:2]\n",
    "    \n",
    "    # Define the new image dimensions for EAST input\n",
    "    newW, newH = (320, 320)\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    \n",
    "    # Resize the image for EAST\n",
    "    img = cv2.resize(img, (newW, newH))\n",
    "\n",
    "    # Load the EAST model\n",
    "    net = cv2.dnn.readNet(east_model_path)\n",
    "\n",
    "    # Prepare the image for the EAST model\n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0, (newW, newH), \n",
    "                                 (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Get scores and geometry data from the model\n",
    "    (scores, geometry) = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \n",
    "                                      \"feature_fusion/concat_3\"])\n",
    "    \n",
    "    # Decode the predictions to extract the bounding boxes\n",
    "    rectangles, confidences = decode_predictions(scores, geometry, 0.5)\n",
    "\n",
    "    # Apply non-maxima suppression to remove overlapping boxes\n",
    "    boxes = non_max_suppression(np.array(rectangles), probs=confidences)\n",
    "    \n",
    "    # Scale bounding boxes back to original image size\n",
    "    boxes = [(int(rH * startX), int(rW * startY), int(rH * endX), int(rW * endY))\n",
    "             for (startX, startY, endX, endY) in boxes]\n",
    "\n",
    "    # Initialize the OCR model (PaddleOCR)\n",
    "    ocr_model = PaddleOCR(use_angle_cls=True, lang='en')  # English language model\n",
    "\n",
    "    # Iterate over the detected text regions\n",
    "    for i, (startX, startY, endX, endY) in enumerate(boxes):\n",
    "        # Crop the image using the detected coordinates\n",
    "        cropped_image = orig[startY:endY, startX:endX]\n",
    "        \n",
    "        # Save the cropped image to a temporary location (optional, for debugging)\n",
    "        cropped_image_path = f\"cropped_image_{i}.jpg\"\n",
    "        cv2.imwrite(cropped_image_path, cropped_image)\n",
    "        \n",
    "        # Use OCR on the cropped image to extract text\n",
    "        result = ocr_model.ocr(cropped_image_path, cls=True)\n",
    "        \n",
    "        # Extract the recognized text\n",
    "        if result and result[0]:\n",
    "            extracted_text = [line[1][0] for line in result[0]]\n",
    "            print(f\"Extracted text from region {i + 1}: {''.join(extracted_text)}\")\n",
    "        else:\n",
    "            print(f\"No text detected in region {i + 1}\")\n",
    "\n",
    "# Example usage:\n",
    "image_path = r'C:\\Users\\archi\\Downloads\\processed_images\\processed_images\\51NIEOGNLSS.jpg'  # Path to your input image\n",
    "east_model_path = r'C:\\Users\\archi\\Downloads\\frozen_east_text_detection\\frozen_east_text_detection.pb'  # Path to the EAST model\n",
    "\n",
    "# Call the function to detect text and extract the text from detected regions\n",
    "detect_and_extract_text(image_path, east_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/11/29 23:24:40] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\archi/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\archi/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\archi\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\archi/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.019997358322143555\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: cls num  : 1, elapsed : 0.011998891830444336\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: rec_res num  : 1, elapsed : 0.04600381851196289\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.020120620727539062\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: rec_res num  : 0, elapsed : 0.0\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.023000001907348633\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: cls num  : 1, elapsed : 0.008002519607543945\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: rec_res num  : 1, elapsed : 0.04200410842895508\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.018513202667236328\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: cls num  : 1, elapsed : 0.010000467300415039\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: rec_res num  : 1, elapsed : 0.034998178482055664\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.011999130249023438\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: cls num  : 1, elapsed : 0.007005453109741211\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: rec_res num  : 1, elapsed : 0.03951311111450195\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.023462533950805664\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: cls num  : 1, elapsed : 0.04500913619995117\n",
      "[2024/11/29 23:24:41] ppocr DEBUG: rec_res num  : 1, elapsed : 0.04951071739196777\n"
     ]
    }
   ],
   "source": [
    "#final code with saving into the csv\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from paddleocr import PaddleOCR\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "# EAST Text Detection\n",
    "def decode_predictions(scores, geometry, min_confidence=0.5):\n",
    "    (num_rows, num_cols) = scores.shape[2:4]\n",
    "    rectangles = []\n",
    "    confidences = []\n",
    "    \n",
    "    for y in range(0, num_rows):\n",
    "        scores_data = scores[0, 0, y]\n",
    "        x_data0 = geometry[0, 0, y]\n",
    "        x_data1 = geometry[0, 1, y]\n",
    "        x_data2 = geometry[0, 2, y]\n",
    "        x_data3 = geometry[0, 3, y]\n",
    "        angles_data = geometry[0, 4, y]\n",
    "        \n",
    "        for x in range(0, num_cols):\n",
    "            if scores_data[x] < min_confidence:\n",
    "                continue\n",
    "            \n",
    "            offset_x, offset_y = (x * 4.0, y * 4.0)\n",
    "            angle = angles_data[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            \n",
    "            h = x_data0[x] + x_data2[x]\n",
    "            w = x_data1[x] + x_data3[x]\n",
    "            \n",
    "            end_x = int(offset_x + (cos * x_data1[x]) + (sin * x_data2[x]))\n",
    "            end_y = int(offset_y - (sin * x_data1[x]) + (cos * x_data2[x]))\n",
    "            start_x = int(end_x - w)\n",
    "            start_y = int(end_y - h)\n",
    "            \n",
    "            rectangles.append((start_x, start_y, end_x, end_y))\n",
    "            confidences.append(scores_data[x])\n",
    "    \n",
    "    return (rectangles, confidences)\n",
    "\n",
    "# Function to detect text regions using EAST and pass them to OCR\n",
    "def detect_and_extract_text(image_path, east_model_path, csv_writer):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "    orig = img.copy()\n",
    "    (H, W) = img.shape[:2]\n",
    "    \n",
    "    newW, newH = (320, 320)\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    \n",
    "    img = cv2.resize(img, (newW, newH))\n",
    "\n",
    "    net = cv2.dnn.readNet(east_model_path)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0, (newW, newH), \n",
    "                                 (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    (scores, geometry) = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \n",
    "                                      \"feature_fusion/concat_3\"])\n",
    "\n",
    "\n",
    "    rectangles, confidences = decode_predictions(scores, geometry, 0.5)\n",
    "\n",
    "    boxes = non_max_suppression(np.array(rectangles), probs=confidences)\n",
    "    \n",
    "    boxes = [(int(rH * startX), int(rW * startY), int(rH * endX), int(rW * endY))\n",
    "             for (startX, startY, endX, endY) in boxes]\n",
    "\n",
    "    ocr_model = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "    # Regex pattern for matching entity values\n",
    "    pattern = re.compile(r'\\b\\d+(\\.\\d+)?(g|G|ml|v|kg|oz|mg|Mg|MG|L|cm|W)\\b', re.IGNORECASE)\n",
    "\n",
    "    matched_text = 'null'  # Default value if no match found\n",
    "\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        cropped_image = orig[startY:endY, startX:endX]\n",
    "        \n",
    "        result = ocr_model.ocr(cropped_image, cls=True)\n",
    "        \n",
    "        if result and result[0]:\n",
    "            extracted_text = [line[1][0] for line in result[0]]\n",
    "            text = ''.join(extracted_text)\n",
    "            # Search for matches in the extracted text\n",
    "            match = pattern.search(text)\n",
    "            if match:\n",
    "                matched_text = match.group()\n",
    "                break  # Stop after finding the first match\n",
    "    \n",
    "    # Write the matched text or 'null' to CSV\n",
    "    csv_writer.writerow([image_path, matched_text])\n",
    "\n",
    "# Function to process a list of images and save extracted text to CSV\n",
    "def process_images(image_paths, east_model_path, csv_filename):\n",
    "    # Open the CSV file in 'a' mode for appending. This ensures data is appended to the file.\n",
    "    # The 'w' mode will overwrite, but 'a' mode appends to the file\n",
    "    with open(csv_filename, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Only write the header once, before processing images\n",
    "        if csvfile.tell() == 0:  # Checks if the file is empty (write header if so)\n",
    "            csv_writer.writerow(['Image Path', 'Extracted Text'])  # CSV header\n",
    "        \n",
    "        # Process all images and extract text\n",
    "        for image_path in image_paths:\n",
    "            detect_and_extract_text(image_path, east_model_path, csv_writer)\n",
    "\n",
    "# Example usage:\n",
    "image_paths = [\n",
    "    r'C:\\Users\\archi\\Downloads\\processed_images\\processed_images\\81CAc3ok29L.jpg',\n",
    "    # Add more image paths here\n",
    "]\n",
    "east_model_path = r'C:\\Users\\archi\\Downloads\\frozen_east_text_detection\\frozen_east_text_detection.pb'\n",
    "csv_filename = r'C:\\Users\\archi\\Desktop\\extracted_text.csv'\n",
    "\n",
    "process_images(image_paths, east_model_path, csv_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
